{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38edf6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plexapi.server import PlexServer\n",
    "from tmdbv3api import TMDb, Movie, Genre\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "525f572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = 'http://peterubuntuserver.ddns.net:32400'\n",
    "token = 'ydWQy8X6StWBJVPHiLf2'\n",
    "plex = PlexServer(baseurl, token)\n",
    "\n",
    "tmdb = TMDb()\n",
    "tmdb.api_key = 'ea023fa0879737d0cfd9ae3ca7365a6e'\n",
    "movie_api = Movie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2866a9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "attribute name must be string, not 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 114\u001b[39m\n\u001b[32m    111\u001b[39m tmdb_ids      = get_tmdb_ids(plex)\n\u001b[32m    112\u001b[39m top_actors, top_directors = build_counters(tmdb_ids)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m vectors = \u001b[43mbuild_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_actors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_directors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m seed = \u001b[33m\"\u001b[39m\u001b[33mInception\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m title, score \u001b[38;5;129;01min\u001b[39;00m recommend(seed, vectors, top_n=\u001b[32m5\u001b[39m):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 87\u001b[39m, in \u001b[36mbuild_dataset\u001b[39m\u001b[34m(plex, movie_api, top_actors, top_directors)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     86\u001b[39m content_vecs.append(\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[43mvectorize_movie\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenres_master\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_actors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_directors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m )\n\u001b[32m     89\u001b[39m overviews.append(md.overview \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     90\u001b[39m titles.append(pm.title)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mvectorize_movie\u001b[39m\u001b[34m(md, creds, genres_master, top_actors, top_directors)\u001b[39m\n\u001b[32m     48\u001b[39m v += [\n\u001b[32m     49\u001b[39m     (year - \u001b[32m1900\u001b[39m) / \u001b[32m125\u001b[39m,\n\u001b[32m     50\u001b[39m     runtime  / \u001b[32m300\u001b[39m,\n\u001b[32m     51\u001b[39m     vote_avg / \u001b[32m10\u001b[39m,\n\u001b[32m     52\u001b[39m ]\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# — cast\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m cast5 = {c[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcreds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m c.get(\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m)}\n\u001b[32m     56\u001b[39m v   += [\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m actor \u001b[38;5;129;01min\u001b[39;00m cast5 \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m actor \u001b[38;5;129;01min\u001b[39;00m top_actors]\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# — directors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\projects\\plex_reccomendation\\reccomendations\\Lib\\site-packages\\tmdbv3api\\as_obj.py:47\u001b[39m, in \u001b[36mAsObj.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._obj_list[key]\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, key)\n",
      "\u001b[31mTypeError\u001b[39m: attribute name must be string, not 'slice'"
     ]
    }
   ],
   "source": [
    "def get_tmdb_ids(plex):\n",
    "    ids = []\n",
    "    for m in plex.library.section('Movies').all():\n",
    "        for guid in m.guids:\n",
    "            if guid.id.startswith('tmdb://'):\n",
    "                try:\n",
    "                    tmdb_str = guid.id.split('//')[-1].split('?')[0]\n",
    "                    ids.append(int(tmdb_str))\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                break\n",
    "    return ids\n",
    "\n",
    "def build_counters(tmdb_ids, top_n_actors=500, top_n_directors=200):\n",
    "    actor_ctr, director_ctr = Counter(), Counter()\n",
    "    for tid in tmdb_ids:\n",
    "        try:\n",
    "            creds = movie_api.credits(tid)\n",
    "            cast = list(creds.cast)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        # cast is a list of dicts\n",
    "        for a in cast[:5]:\n",
    "            name = a.get('name')\n",
    "            if name:\n",
    "                actor_ctr[name] += 1\n",
    "\n",
    "        # crew is a list of dicts\n",
    "        for c in creds.crew:\n",
    "            if c.get('job') == 'Director' and c.get('name'):\n",
    "                director_ctr[c['name']] += 1\n",
    "\n",
    "    top_actors   = [name for name, _ in actor_ctr.most_common(top_n_actors)]\n",
    "    top_directors= [name for name, _ in director_ctr.most_common(top_n_directors)]\n",
    "    return top_actors, top_directors\n",
    "\n",
    "def vectorize_movie(md, creds, genres_master, top_actors, top_directors):\n",
    "    v = []\n",
    "    # — one-hot genres\n",
    "    movie_genres = {g.name for g in md.genres}\n",
    "    v += [1 if gm in movie_genres else 0 for gm in genres_master]\n",
    "\n",
    "    # — normalized numeric\n",
    "    year     = int(md.release_date[:4]) if md.release_date else 2000\n",
    "    runtime  = md.runtime  or 90\n",
    "    vote_avg = md.vote_average or 5\n",
    "    v += [\n",
    "        (year - 1900) / 125,\n",
    "        runtime  / 300,\n",
    "        vote_avg / 10,\n",
    "    ]\n",
    "\n",
    "    # — cast\n",
    "    cast5 = {c['name'] for c in creds.cast[:5] if c.get('name')}\n",
    "    v   += [1 if actor in cast5 else 0 for actor in top_actors]\n",
    "\n",
    "    # — directors\n",
    "    dirs = {c['name'] for c in creds.crew if c.get('job')=='Director' and c.get('name')}\n",
    "    v   += [1 if d in dirs else 0 for d in top_directors]\n",
    "\n",
    "    return np.array(v, dtype=float)\n",
    "\n",
    "def build_dataset(plex, movie_api, top_actors, top_directors):\n",
    "    genres_master = [g.name for g in Genre().movie_list()]\n",
    "\n",
    "    content_vecs, overviews, titles = [], [], []\n",
    "    for pm in plex.library.section('Movies').all():\n",
    "        tmdb_id = None\n",
    "        for guid in pm.guids:\n",
    "            if guid.id.startswith('tmdb://'):\n",
    "                try:\n",
    "                    tmdb_id = int(guid.id.split('//')[-1].split('?')[0])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                break\n",
    "        if tmdb_id is None:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            md    = movie_api.details(tmdb_id)\n",
    "            creds = movie_api.credits(tmdb_id)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        content_vecs.append(\n",
    "            vectorize_movie(md, creds, genres_master, top_actors, top_directors)\n",
    "        )\n",
    "        overviews.append(md.overview or \"\")\n",
    "        titles.append(pm.title)\n",
    "\n",
    "    content_matrix = np.vstack(content_vecs)\n",
    "\n",
    "    # TF-IDF on plot + SVD\n",
    "    tfidf = TfidfVectorizer(max_features=2000, stop_words='english')\n",
    "    X_tfidf = tfidf.fit_transform(overviews)\n",
    "    svd     = TruncatedSVD(n_components=200, random_state=42)\n",
    "    X_text  = svd.fit_transform(X_tfidf)\n",
    "\n",
    "    X_all = np.hstack([content_matrix, X_text])\n",
    "    return { titles[i]: X_all[i] for i in range(len(titles)) }\n",
    "\n",
    "def recommend(title, vectors, top_n=5):\n",
    "    all_titles = list(vectors)\n",
    "    mat        = np.vstack([vectors[t] for t in all_titles])\n",
    "    target     = vectors[title].reshape(1, -1)\n",
    "    sims       = cosine_similarity(target, mat)[0]\n",
    "    best_idxs  = sims.argsort()[::-1][1:top_n+1]\n",
    "    return [(all_titles[i], sims[i]) for i in best_idxs]\n",
    "\n",
    "tmdb_ids      = get_tmdb_ids(plex)\n",
    "top_actors, top_directors = build_counters(tmdb_ids)\n",
    "\n",
    "vectors = build_dataset(plex, movie_api, top_actors, top_directors)\n",
    "\n",
    "seed = \"Inception\"\n",
    "for title, score in recommend(seed, vectors, top_n=5):\n",
    "    print(f\"{title:<40}  sim={score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "832e7a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating_key</th>\n",
       "      <th>watched_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22851609</td>\n",
       "      <td>612</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>514171027</td>\n",
       "      <td>560</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22851609</td>\n",
       "      <td>1050</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22851609</td>\n",
       "      <td>1923</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27840798</td>\n",
       "      <td>560</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22851609</td>\n",
       "      <td>1271</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>486175841</td>\n",
       "      <td>561</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>514171027</td>\n",
       "      <td>2457</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22851609</td>\n",
       "      <td>272</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>486175841</td>\n",
       "      <td>5335</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22851609</td>\n",
       "      <td>1128</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22851609</td>\n",
       "      <td>1128</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22851609</td>\n",
       "      <td>1515</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22851609</td>\n",
       "      <td>1995</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22851609</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  rating_key  watched_status\n",
       "0    22851609         612            1.00\n",
       "1   514171027         560            0.25\n",
       "2    22851609        1050            1.00\n",
       "3    22851609        1923            1.00\n",
       "4    27840798         560            1.00\n",
       "5    22851609        1271            0.50\n",
       "6   486175841         561            0.50\n",
       "7   514171027        2457            0.50\n",
       "8    22851609         272            0.00\n",
       "9   486175841        5335            0.25\n",
       "10   22851609        1128            1.00\n",
       "11   22851609        1128            1.00\n",
       "12   22851609        1515            1.00\n",
       "13   22851609        1995            0.00\n",
       "14   22851609           5            0.75"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "TAUTULLI_URL  = \"http://192.168.2.73:8181\"      # ⚠️  change if remote / SSL\n",
    "TAUTULLI_KEY  = \"c0766a7cd7a24f73b8d110a118fed994\"      # ⚠️  copy from Tautulli settings\n",
    "MAX_HISTORY   = None     # None = fetch every record; else int for quick tests\n",
    "BATCH_SIZE    = 1000 \n",
    "\n",
    "def fetch_history_tautulli(url=TAUTULLI_URL, apikey=TAUTULLI_KEY,\n",
    "                           media_type=\"movie\", limit=MAX_HISTORY,\n",
    "                           batch=BATCH_SIZE):\n",
    "    \"\"\"Return a DataFrame with at least user_id, rating_key, watched_status.\"\"\"\n",
    "    rows, start, keep_going = [], 0, True\n",
    "    while keep_going:\n",
    "        params = {\n",
    "            \"apikey\": apikey,\n",
    "            \"cmd\": \"get_history\",\n",
    "            \"media_type\": media_type,\n",
    "            \"length\": batch,\n",
    "            \"start\": start,\n",
    "            \"order_column\": \"date\",\n",
    "            \"order_dir\": \"asc\",\n",
    "        }\n",
    "        r = requests.get(f\"{url}/api/v2\", params=params, timeout=20).json()\n",
    "        if r[\"response\"][\"result\"] != \"success\":\n",
    "            raise RuntimeError(r[\"response\"][\"message\"])\n",
    "        data = r[\"response\"][\"data\"][\"data\"]\n",
    "        rows.extend(data)\n",
    "        start += batch\n",
    "        keep_going = data and (limit is None or start < limit)\n",
    "    return pd.DataFrame(rows)[[\"user_id\", \"rating_key\", \"watched_status\"]]\n",
    "\n",
    "fetch_history_tautulli()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685bbb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids            = get_tmdb_ids(plex)\n",
    "top_actors, top_directors = build_counters(ids)\n",
    "vectors        = build_dataset(plex, movie_api, top_actors, top_directors)\n",
    "\n",
    "seed = \"Inception\"\n",
    "for t, score in recommend(seed, vectors, top_n=5):\n",
    "    print(f\"{t:<40}  sim={score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b57b20bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = build_dataset(movie_api, movie_library,\n",
    "                        top_actors, top_directors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "074d2390",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 116\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# 4. Build feature matrix and index\u001b[39;00m\n\u001b[32m    115\u001b[39m X   = build_features(df)\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m knn = \u001b[43mtrain_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# Demo\u001b[39;00m\n\u001b[32m    119\u001b[39m seed = \u001b[33m\"\u001b[39m\u001b[33mInception\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mtrain_index\u001b[39m\u001b[34m(X)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_index\u001b[39m(X):\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     knn = \u001b[43mNearestNeighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcosine\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m knn\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\projects\\plex_reccomendation\\reccomendations\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\projects\\plex_reccomendation\\reccomendations\\Lib\\site-packages\\sklearn\\neighbors\\_unsupervised.py:179\u001b[39m, in \u001b[36mNearestNeighbors.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# NearestNeighbors.metric is not validated yet\u001b[39;00m\n\u001b[32m    160\u001b[39m     prefer_skip_nested_validation=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    161\u001b[39m )\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    163\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit the nearest neighbors estimator from the training dataset.\u001b[39;00m\n\u001b[32m    164\u001b[39m \n\u001b[32m    165\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    177\u001b[39m \u001b[33;03m        The fitted nearest neighbors estimator.\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\projects\\plex_reccomendation\\reccomendations\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:526\u001b[39m, in \u001b[36mNeighborsBase._fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    525\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m         X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m            \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m            \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m            \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[38;5;28mself\u001b[39m._check_algorithm_metric()\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metric_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\projects\\plex_reccomendation\\reccomendations\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2942\u001b[39m         out = X, y\n\u001b[32m   2943\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\projects\\plex_reccomendation\\reccomendations\\Lib\\site-packages\\sklearn\\utils\\validation.py:1055\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1053\u001b[39m         array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1054\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1055\u001b[39m         array = \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1057\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1058\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.format(array)\n\u001b[32m   1059\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\Documents\\projects\\plex_reccomendation\\reccomendations\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:839\u001b[39m, in \u001b[36m_asarray_with_order\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    837\u001b[39m     array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m     array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    841\u001b[39m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray(array)\n",
      "\u001b[31mValueError\u001b[39m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plexapi.server import PlexServer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "TMDB_API_KEY='ea023fa0879737d0cfd9ae3ca7365a6e'\n",
    "\n",
    "def fetch_plex_list():\n",
    "    \"\"\"Get title+tmdb_id for every movie in Plex.\"\"\"\n",
    "    rows = []\n",
    "    for m in plex.library.section(\"Movies\").all():\n",
    "        tmdb_id = None\n",
    "        for g in m.guids:\n",
    "            if \"tmdb\" in g.id:\n",
    "                tmdb_id = g.id.split(\"//\")[-1].split(\"?\")[0]\n",
    "                break\n",
    "        if tmdb_id:\n",
    "            rows.append({\"title\": m.title, \"tmdb_id\": tmdb_id})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def tmdb_get(path, **params):\n",
    "    \"\"\"Helper to call TMDb v3 API and return .json().\"\"\"\n",
    "    url = f\"https://api.themoviedb.org/3{path}\"\n",
    "    params[\"api_key\"] = TMDB_API_KEY\n",
    "    return requests.get(url, params=params).json()\n",
    "\n",
    "\n",
    "def enrich_with_tmdb(df):\n",
    "    \"\"\"Add overview, genres, runtime, vote, release_date, cast, directors.\"\"\"\n",
    "    meta = []\n",
    "    for _, row in df.iterrows():\n",
    "        tid = row[\"tmdb_id\"]\n",
    "        info = tmdb_get(f\"/movie/{tid}\", language=\"en-US\")\n",
    "        creds = tmdb_get(f\"/movie/{tid}/credits\")\n",
    "        genres = [g[\"name\"] for g in info.get(\"genres\", [])]\n",
    "        overview = info.get(\"overview\", \"\") or \"\"\n",
    "        runtime = info.get(\"runtime\") or 0\n",
    "        vote = info.get(\"vote_average\") or 0\n",
    "        rd = info.get(\"release_date\") or \"\"\n",
    "        # top 5 cast names\n",
    "        cast5 = [c[\"name\"] for c in creds.get(\"cast\", [])[:5] if c.get(\"name\")]\n",
    "        # all directors\n",
    "        dirs = [c[\"name\"] for c in creds.get(\"crew\", []) if c.get(\"job\") == \"Director\"]\n",
    "        meta.append({\n",
    "            \"overview\": overview,\n",
    "            \"genres\": genres,\n",
    "            \"runtime\": runtime,\n",
    "            \"vote\": vote,\n",
    "            \"release_date\": rd,\n",
    "            \"cast\": cast5,\n",
    "            \"directors\": dirs\n",
    "        })\n",
    "    return pd.DataFrame(meta)\n",
    "\n",
    "\n",
    "def build_features(df):\n",
    "    # 1️⃣ MultiLabelBinarizers for genres, cast, directors\n",
    "    mlb_genre = MultiLabelBinarizer(sparse_output=False)\n",
    "    G = mlb_genre.fit_transform(df[\"genres\"])\n",
    "\n",
    "    mlb_cast = MultiLabelBinarizer(sparse_output=False, classes=None)\n",
    "    C = mlb_cast.fit_transform(df[\"cast\"])\n",
    "\n",
    "    mlb_dir = MultiLabelBinarizer(sparse_output=False)\n",
    "    D = mlb_dir.fit_transform(df[\"directors\"])\n",
    "\n",
    "    # 2️⃣ Numeric features: runtime, vote, year\n",
    "    years = df[\"release_date\"].str[:4].fillna(\"2000\").astype(int)\n",
    "    nums = np.vstack([df[\"runtime\"], df[\"vote\"], years]).T\n",
    "    scaler = MinMaxScaler()\n",
    "    N = scaler.fit_transform(nums)\n",
    "\n",
    "    # 3️⃣ TF-IDF on overview + SVD → 100 dims\n",
    "    tfidf = TfidfVectorizer(max_features=2000, stop_words=\"english\")\n",
    "    Xtxt = tfidf.fit_transform(df[\"overview\"])\n",
    "    svd  = TruncatedSVD(n_components=100, random_state=42)\n",
    "    Ttxt = svd.fit_transform(Xtxt)\n",
    "\n",
    "    # 4️⃣ Stack everything\n",
    "    X = np.hstack([G, C, D, N, Ttxt])\n",
    "    return X, (mlb_genre, mlb_cast, mlb_dir, scaler, tfidf, svd)\n",
    "\n",
    "\n",
    "def train_index(X):\n",
    "    knn = NearestNeighbors(n_neighbors=6, metric=\"cosine\").fit(X)\n",
    "    return knn\n",
    "\n",
    "\n",
    "def recommend(title, df, X, knn):\n",
    "    if \"title\" not in df.columns:\n",
    "        raise KeyError(\"DataFrame must have a 'title' column\")\n",
    "    idxs = df.index[df[\"title\"] == title].tolist()\n",
    "    if not idxs:\n",
    "        raise ValueError(f\"'{title}' not found in your library\")\n",
    "    dist, nn = knn.kneighbors(X[idxs[0]].reshape(1, -1), n_neighbors=6)\n",
    "    recs = df.iloc[nn[0]][[\"title\"]].copy()\n",
    "    recs[\"score\"] = 1 - dist[0]\n",
    "    return recs.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "df_movies = fetch_plex_list()\n",
    "\n",
    "# 2. Fetch all metadata from TMDb\n",
    "df_meta   = enrich_with_tmdb(df_movies)\n",
    "\n",
    "# 3. Stitch them together so we keep \"title\"\n",
    "df = pd.concat([df_movies.reset_index(drop=True),\n",
    "                df_meta.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# 4. Build feature matrix and index\n",
    "X   = build_features(df)\n",
    "knn = train_index(X)\n",
    "\n",
    "# Demo\n",
    "seed = \"Inception\"\n",
    "print(f\"\\nRecommendations for {seed!r}:\")\n",
    "print(recommend(seed, df, X, knn).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reccomendations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
